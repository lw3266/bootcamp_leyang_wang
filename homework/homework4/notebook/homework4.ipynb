{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. API Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131382/3517850085.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_raw = yf.download(SYMBOL, period=\"5d\", interval=\"1m\")\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                           Close        High         Low        Open  \\\n",
      "Ticker                           NVDA        NVDA        NVDA        NVDA   \n",
      "Datetime                                                                    \n",
      "2025-08-14 13:30:00+00:00  179.756699  180.570007  179.740005  179.794998   \n",
      "2025-08-14 13:31:00+00:00  180.549194  180.819000  179.460007  179.756500   \n",
      "2025-08-14 13:32:00+00:00  180.892502  180.960007  180.479996  180.559998   \n",
      "2025-08-14 13:33:00+00:00  180.070007  180.649994  180.050003  180.610001   \n",
      "2025-08-14 13:34:00+00:00  180.520004  180.580002  179.727005  180.085007   \n",
      "...                               ...         ...         ...         ...   \n",
      "2025-08-20 19:55:00+00:00  175.384995  175.529907  175.050003  175.100006   \n",
      "2025-08-20 19:56:00+00:00  175.279999  175.419998  175.264999  175.380005   \n",
      "2025-08-20 19:57:00+00:00  175.449997  175.490005  175.270004  175.274994   \n",
      "2025-08-20 19:58:00+00:00  175.365005  175.460007  175.339996  175.449997   \n",
      "2025-08-20 19:59:00+00:00  175.389999  175.490005  175.320007  175.365005   \n",
      "\n",
      "Price                       Volume  \n",
      "Ticker                        NVDA  \n",
      "Datetime                            \n",
      "2025-08-14 13:30:00+00:00  7309885  \n",
      "2025-08-14 13:31:00+00:00  1317429  \n",
      "2025-08-14 13:32:00+00:00   394544  \n",
      "2025-08-14 13:33:00+00:00  1588213  \n",
      "2025-08-14 13:34:00+00:00  1009619  \n",
      "...                            ...  \n",
      "2025-08-20 19:55:00+00:00  1346195  \n",
      "2025-08-20 19:56:00+00:00   866693  \n",
      "2025-08-20 19:57:00+00:00   919527  \n",
      "2025-08-20 19:58:00+00:00   950857  \n",
      "2025-08-20 19:59:00+00:00  1919628  \n",
      "\n",
      "[1940 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "SYMBOL = \"NVDA\"\n",
    "df_raw = yf.download(SYMBOL, period=\"5d\", interval=\"1m\")\n",
    "\n",
    "print(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'missing_cols': \"Missing columns: ['ticker']\",\n",
       " 'na_total': 'Total NA values: 0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "\n",
    "def validate_df(df: pd.DataFrame, required_cols: List[str], dtypes_map: Dict[str, str]) -> Dict[str, str]:\n",
    "    msgs = {}\n",
    "    required_cols = [col.lower() for col in required_cols] # make required columns lower case\n",
    "    df_cols_lower = [str(col).lower() for col in df.columns] # does not modify the df columns, only to make it case insensitive for validation\n",
    "    missing = [\n",
    "        col for col in required_cols\n",
    "        if not any(col.lower() in str(item).lower() for tup in df.columns for item in tup) # since the column names are in tuples, eg: \"('open', 'nvda')\", I can not simply setting equal signs to see if the column exist\n",
    "    ]\n",
    "    if missing:\n",
    "        msgs['missing_cols'] = f\"Missing columns: {missing}\"\n",
    "    for col, dtype in dtypes_map.items():\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                if dtype == 'datetime64[ns]':\n",
    "                    pd.to_datetime(df[col])\n",
    "                elif dtype == 'float':\n",
    "                    pd.to_numeric(df[col])\n",
    "            except Exception as e:\n",
    "                msgs[f'dtype_{col}'] = f\"Failed to coerce {col} to {dtype}: {e}\"\n",
    "    na_counts = df.isna().sum().sum()\n",
    "    msgs['na_total'] = f\"Total NA values: {na_counts}\"\n",
    "    return msgs\n",
    "\n",
    "required_cols = list([\"open\", \"close\", \"high\", \"low\", \"ticker\"])\n",
    "validate_df(df_raw, required_cols, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scrape a Small Table (Needs Fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no table found\n",
      "{'na_total': 'Total NA values: 19259'}\n",
      "                  col_0                  col_1 col_2 col_3 col_4 col_5 col_6\n",
      "0     Namespace Prefix:                   dei_   NaN   NaN   NaN   NaN   NaN\n",
      "1            Data Type:  xbrli:booleanItemType   NaN   NaN   NaN   NaN   NaN\n",
      "2         Balance Type:                     na   NaN   NaN   NaN   NaN   NaN\n",
      "3          Period Type:               duration   NaN   NaN   NaN   NaN   NaN\n",
      "4     Namespace Prefix:                   dei_   NaN   NaN   NaN   NaN   NaN\n",
      "...                 ...                    ...   ...   ...   ...   ...   ...\n",
      "3896         Data Type:                     na   NaN   NaN   NaN   NaN   NaN\n",
      "3897  Namespace Prefix:                    NaN   NaN   NaN   NaN   NaN   NaN\n",
      "3898      Balance Type:                    NaN   NaN   NaN   NaN   NaN   NaN\n",
      "3899       Period Type:                    NaN   NaN   NaN   NaN   NaN   NaN\n",
      "3900         Data Type:                     na   NaN   NaN   NaN   NaN   NaN\n",
      "\n",
      "[3901 rows x 7 columns]\n",
      "Saved to data\n"
     ]
    }
   ],
   "source": [
    "import requests, datetime, os\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def safe_stamp():\n",
    "    return datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def safe_filename(prefix: str, meta: Dict[str, str]) -> str:\n",
    "    mid = \"_\".join([f\"{k}-{str(v).replace(' ', '-')[:20]}\" for k, v in meta.items()])\n",
    "    return f\"{prefix}_{mid}_{safe_stamp()}.csv\"\n",
    "\n",
    "load_dotenv()\n",
    "rootPath = os.getenv(\"PROJECT_ROOT\")\n",
    "SCRAPE_URL = \"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001045810/b2bd9f31-ce6e-4f50-bb51-8d433e958103.html#\"\n",
    "headers = {\"User-Agent\": \"AFE-Course-Notebook/1.0 (contact: instructor@example.edu)\"}\n",
    "DATA_RAW = Path(rootPath) / \"data/raw\"\n",
    "\n",
    "try:\n",
    "    resp = requests.get(SCRAPE_URL, headers=headers, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    tables = soup.find_all('table')\n",
    "    df_scrape = pd.DataFrame()\n",
    "    for idx, table in enumerate(tables, start=1):\n",
    "        rows = []\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            cells = []\n",
    "            for td in tr.find_all([\"td\", \"th\"]):\n",
    "                # get_text joins text from all nested tags with spaces\n",
    "                text = td.get_text(\" \", strip=True)\n",
    "                if text or td.find():  # ignore truly empty cells\n",
    "                    cells.append(text)\n",
    "            if cells:\n",
    "                rows.append(cells)\n",
    "\n",
    "        if rows:\n",
    "            header = [f\"col_{i}\" for i in range(len(rows[0]))]\n",
    "            data = [r for r in rows[1:] if len(r) == len(header)] # check header and data are of same columns sizes\n",
    "            df = pd.DataFrame(data, columns=header)\n",
    "            df_scrape = pd.concat([df_scrape, df], ignore_index=True)\n",
    "    else:\n",
    "        print(\"no table found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Scrape failed: \", e)\n",
    "\n",
    "# if 'Price' in df_scrape.columns:\n",
    "#     df_scrape['Price'] = pd.to_numeric(df_scrape['Price'], errors='coerce')\n",
    "\n",
    "msgs2 = validate_df(df_scrape, required_cols=list([]), dtypes_map={})\n",
    "print(msgs2)\n",
    "\n",
    "print(df_scrape)\n",
    "if not df_scrape.empty:\n",
    "    fname2 = safe_filename(prefix=\"scrape\", meta={\"site\": \"example\", \"table\": \"markets\"})\n",
    "    out_path2 = DATA_RAW / fname2\n",
    "    df_scrape.to_csv(out_path2, index=False)\n",
    "    print(\"Saved to data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - For validation logic and output, please see the second step and helper functions in the first step.\n",
    "\n",
    " - source: Nvidia 10-K report, Fed 26 2025, link: https://www.sec.gov/Archives/edgar/data/1045810/000104581025000023/nvda-20250126.htm\n",
    " \n",
    "  - .env.example will be committed, but .env should not \n",
    "  - Counted missing values\n",
    "  - Confirmed row matches column dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions % Risks\n",
    "\n",
    " - the data is assumed to be accurate\n",
    " - the parsed content might be incorrect and requires manual checking\n",
    " - sec.gov might not be accessible in the future"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
